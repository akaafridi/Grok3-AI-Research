{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JrgrPjAWUiD4",
        "outputId": "2adbe2e6-b5fc-43fe-e0ee-374e590bd818"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dense Baseline: 1.041147 sec/step\n",
            "FP8 Only: 0.804552 sec/step\n",
            "MoE Only: 2.577101 sec/step\n",
            "QLoRA Only: 0.731166 sec/step\n",
            "FP8 + MoE: 2.313285 sec/step\n",
            "FP8 + MoE + QLoRA: 2.144114 sec/step\n",
            "\n",
            "Results saved to: integration_ablation/integration_ablation_results.txt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import time\n",
        "import os\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# Create folder if not exists\n",
        "os.makedirs(\"integration_ablation\", exist_ok=True)\n",
        "\n",
        "# Simulate FP8 Quantization manually\n",
        "def simulate_fp8(x):\n",
        "    x = torch.clamp(x, min=-1.0, max=1.0)\n",
        "    return (x * 127).round() / 127\n",
        "\n",
        "# LoRA Adapter for Fine-Tuning\n",
        "class LoRAAdapter(nn.Module):\n",
        "    def __init__(self, original_layer, rank=8):\n",
        "        super().__init__()\n",
        "        self.original_layer = original_layer\n",
        "        self.lora_A = nn.Linear(original_layer.in_features, rank, bias=False)\n",
        "        self.lora_B = nn.Linear(rank, original_layer.out_features, bias=False)\n",
        "        for param in self.original_layer.parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.original_layer(x) + self.lora_B(self.lora_A(x))\n",
        "\n",
        "# Mixture of Experts Router\n",
        "class MoERouter(nn.Module):\n",
        "    def __init__(self, input_dim, num_experts):\n",
        "        super().__init__()\n",
        "        self.router = nn.Linear(input_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.router(x)\n",
        "        top2_vals, top2_indices = torch.topk(logits, k=2, dim=-1)\n",
        "        weights = F.softmax(top2_vals, dim=-1)\n",
        "        return top2_indices, weights\n",
        "\n",
        "# Expert Network\n",
        "class Expert(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.ffn = nn.Sequential(\n",
        "            nn.Linear(input_dim, hidden_dim),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n",
        "\n",
        "# Full Integrated Model\n",
        "class IntegratedModel(nn.Module):\n",
        "    def __init__(self, embed_dim, hidden_dim, num_experts, use_fp8=False, use_moe=False, use_lora=False):\n",
        "        super().__init__()\n",
        "        self.use_fp8 = use_fp8\n",
        "        self.use_moe = use_moe\n",
        "        self.use_lora = use_lora\n",
        "\n",
        "        self.q_proj = nn.Linear(embed_dim, embed_dim)\n",
        "        self.v_proj = nn.Linear(embed_dim, embed_dim)\n",
        "\n",
        "        if self.use_lora:\n",
        "            self.q_proj = LoRAAdapter(self.q_proj)\n",
        "            self.v_proj = LoRAAdapter(self.v_proj)\n",
        "\n",
        "        if self.use_moe:\n",
        "            self.router = MoERouter(embed_dim, num_experts)\n",
        "            self.experts = nn.ModuleList([Expert(embed_dim, hidden_dim) for _ in range(num_experts)])\n",
        "        else:\n",
        "            self.ffn = nn.Sequential(\n",
        "                nn.Linear(embed_dim, hidden_dim),\n",
        "                nn.ReLU(),\n",
        "                nn.Linear(hidden_dim, embed_dim)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        if self.use_fp8:\n",
        "            x = simulate_fp8(x)\n",
        "\n",
        "        q = self.q_proj(x)\n",
        "        v = self.v_proj(x)\n",
        "\n",
        "        if self.use_moe:\n",
        "            top2_indices, weights = self.router(x)\n",
        "            output = torch.zeros_like(x)\n",
        "            for i in range(2):\n",
        "                expert_idx = top2_indices[..., i]\n",
        "                weight = weights[..., i].unsqueeze(-1)\n",
        "                expert_outputs = []\n",
        "                for b in range(x.size(0)):\n",
        "                    expert = self.experts[expert_idx[b, 0].item()]\n",
        "                    expert_outputs.append(expert(x[b:b+1]))\n",
        "                expert_outputs = torch.cat(expert_outputs, dim=0)\n",
        "                output += expert_outputs * weight\n",
        "        else:\n",
        "            output = self.ffn(x)\n",
        "\n",
        "        return q + v + output\n",
        "\n",
        "# Benchmarking\n",
        "def benchmark(model, input_tensor):\n",
        "    optimizer = torch.optim.AdamW(filter(lambda p: p.requires_grad, model.parameters()), lr=1e-3)\n",
        "    model.train()\n",
        "    start = time.time()\n",
        "    for _ in range(5):\n",
        "        optimizer.zero_grad()\n",
        "        output = model(input_tensor)\n",
        "        loss = output.mean()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "    end = time.time()\n",
        "    avg_time = (end - start) / 5\n",
        "    return avg_time\n",
        "\n",
        "# Create input\n",
        "batch_size = 8\n",
        "seq_len = 128\n",
        "embed_dim = 1024\n",
        "hidden_dim = 4096\n",
        "num_experts = 16\n",
        "input_tensor = torch.randn(batch_size, seq_len, embed_dim)\n",
        "\n",
        "# Test configurations\n",
        "configs = {\n",
        "    \"Dense Baseline\": {\"use_fp8\": False, \"use_moe\": False, \"use_lora\": False},\n",
        "    \"FP8 Only\": {\"use_fp8\": True, \"use_moe\": False, \"use_lora\": False},\n",
        "    \"MoE Only\": {\"use_fp8\": False, \"use_moe\": True, \"use_lora\": False},\n",
        "    \"QLoRA Only\": {\"use_fp8\": False, \"use_moe\": False, \"use_lora\": True},\n",
        "    \"FP8 + MoE\": {\"use_fp8\": True, \"use_moe\": True, \"use_lora\": False},\n",
        "    \"FP8 + MoE + QLoRA\": {\"use_fp8\": True, \"use_moe\": True, \"use_lora\": True},\n",
        "}\n",
        "\n",
        "results = {}\n",
        "\n",
        "for name, flags in configs.items():\n",
        "    model = IntegratedModel(embed_dim, hidden_dim, num_experts, **flags)\n",
        "    avg_time = benchmark(model, input_tensor)\n",
        "    results[name] = avg_time\n",
        "    print(f\"{name}: {avg_time:.6f} sec/step\")\n",
        "\n",
        "# Save results\n",
        "result_text = \"=== Integration + Ablation Benchmark Results ===\\n\\n\"\n",
        "for name, avg_time in results.items():\n",
        "    result_text += f\"{name}: {avg_time:.6f} sec/step\\n\"\n",
        "\n",
        "with open(\"integration_ablation/integration_ablation_results.txt\", \"w\") as f:\n",
        "    f.write(result_text)\n",
        "\n",
        "print(\"\\nResults saved to: integration_ablation/integration_ablation_results.txt\")\n"
      ]
    }
  ]
}