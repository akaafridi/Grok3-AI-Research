{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xrgtc_CwOi5v",
        "outputId": "6d2f06db-54ba-4623-a996-d9506fb0f3e0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== MoE vs Dense Simulation Results ===\n",
            "Average Inference Time (Dense Model): 0.413534 sec\n",
            "Average Inference Time (MoE Top-2 Model): 0.676468 sec\n",
            "Simulated Speedup (Dense → MoE Top-2): 0.61x\n",
            "Active Parameters per Token (Dense): 67108864 (simulated full)\n",
            "Active Parameters per Token (MoE Top-2): 8388608 (2 experts only)\n",
            "\n",
            "Results saved to: moe_experiments/moe_vs_dense_results.txt\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "import os\n",
        "\n",
        "# Create folder if not exists\n",
        "os.makedirs(\"moe_experiments\", exist_ok=True)\n",
        "\n",
        "# MoE Router: Select Top-2 Experts per token\n",
        "class MoERouter(torch.nn.Module):\n",
        "    def __init__(self, input_dim, num_experts):\n",
        "        super().__init__()\n",
        "        self.router = torch.nn.Linear(input_dim, num_experts)\n",
        "\n",
        "    def forward(self, x):\n",
        "        logits = self.router(x)  # [batch, seq_len, num_experts]\n",
        "        top2_vals, top2_indices = torch.topk(logits, k=2, dim=-1)\n",
        "        weights = F.softmax(top2_vals, dim=-1)\n",
        "        return top2_indices, weights\n",
        "\n",
        "# Expert Network: Simple feedforward for each expert\n",
        "class Expert(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.ffn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n",
        "\n",
        "# MoE Model: Top-2 selected experts\n",
        "class MoEModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, num_experts):\n",
        "        super().__init__()\n",
        "        self.router = MoERouter(input_dim, num_experts)\n",
        "        self.experts = torch.nn.ModuleList([Expert(input_dim, hidden_dim) for _ in range(num_experts)])\n",
        "\n",
        "    def forward(self, x):\n",
        "        top2_indices, weights = self.router(x)\n",
        "        output = torch.zeros_like(x)\n",
        "        for i in range(2):  # Top-2 experts\n",
        "            expert_idx = top2_indices[..., i]\n",
        "            weight = weights[..., i].unsqueeze(-1)\n",
        "            expert_outputs = []\n",
        "            for b in range(x.size(0)):\n",
        "                expert = self.experts[expert_idx[b, 0].item()]  # Batch first\n",
        "                expert_outputs.append(expert(x[b:b+1]))\n",
        "            expert_outputs = torch.cat(expert_outputs, dim=0)\n",
        "            output += expert_outputs * weight\n",
        "        return output\n",
        "\n",
        "# Dense Model: Normal feedforward (no MoE)\n",
        "class DenseModel(torch.nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim):\n",
        "        super().__init__()\n",
        "        self.ffn = torch.nn.Sequential(\n",
        "            torch.nn.Linear(input_dim, hidden_dim),\n",
        "            torch.nn.ReLU(),\n",
        "            torch.nn.Linear(hidden_dim, input_dim)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.ffn(x)\n",
        "\n",
        "# Benchmarking function\n",
        "def benchmark(model, input_tensor):\n",
        "    start = time.time()\n",
        "    for _ in range(10):\n",
        "        _ = model(input_tensor)\n",
        "    end = time.time()\n",
        "    avg_time = (end - start) / 10\n",
        "    return avg_time\n",
        "\n",
        "# Create fake input\n",
        "batch_size = 8\n",
        "seq_len = 128\n",
        "embed_dim = 1024\n",
        "hidden_dim = 4096\n",
        "num_experts = 16\n",
        "\n",
        "input_tensor = torch.randn(batch_size, seq_len, embed_dim)\n",
        "\n",
        "# Instantiate models\n",
        "moe_model = MoEModel(embed_dim, hidden_dim, num_experts)\n",
        "dense_model = DenseModel(embed_dim, hidden_dim)\n",
        "\n",
        "# Benchmark both models\n",
        "dense_time = benchmark(dense_model, input_tensor)\n",
        "moe_time = benchmark(moe_model, input_tensor)\n",
        "\n",
        "# Calculate simulated efficiency\n",
        "speedup = dense_time / moe_time\n",
        "\n",
        "# Print results\n",
        "print(\"=== MoE vs Dense Simulation Results ===\")\n",
        "print(f\"Average Inference Time (Dense Model): {dense_time:.6f} sec\")\n",
        "print(f\"Average Inference Time (MoE Top-2 Model): {moe_time:.6f} sec\")\n",
        "print(f\"Simulated Speedup (Dense → MoE Top-2): {speedup:.2f}x\")\n",
        "print(f\"Active Parameters per Token (Dense): {num_experts * embed_dim * hidden_dim} (simulated full)\")\n",
        "print(f\"Active Parameters per Token (MoE Top-2): {2 * embed_dim * hidden_dim} (2 experts only)\")\n",
        "\n",
        "# Save results to file\n",
        "result_text = f\"\"\"\n",
        "=== MoE vs Dense Simulation Results ===\n",
        "\n",
        "Batch Size: {batch_size}\n",
        "Sequence Length: {seq_len}\n",
        "Embedding Dimension: {embed_dim}\n",
        "Hidden Dimension: {hidden_dim}\n",
        "Number of Experts: {num_experts}\n",
        "\n",
        "Average Inference Time (Dense Model): {dense_time:.6f} sec\n",
        "Average Inference Time (MoE Top-2 Model): {moe_time:.6f} sec\n",
        "Simulated Speedup: {speedup:.2f}x\n",
        "\n",
        "Active Parameters per Token (Dense): {num_experts * embed_dim * hidden_dim}\n",
        "Active Parameters per Token (MoE Top-2): {2 * embed_dim * hidden_dim}\n",
        "\"\"\"\n",
        "\n",
        "with open(\"moe_experiments/moe_vs_dense_results.txt\", \"w\") as f:\n",
        "    f.write(result_text)\n",
        "\n",
        "print(\"\\nResults saved to: moe_experiments/moe_vs_dense_results.txt\")\n"
      ]
    }
  ]
}